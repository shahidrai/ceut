# -*- coding: utf-8 -*-
"""Urdu-attention-graph.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PhH8xfzNnvGl--aNWjvvT5PLnBUTfVMY
"""

!pip3 install  arabic_reshaper

!pip3 install  python-bidi

!pip3 install  torch

import matplotlib.pyplot as plt
from bidi.algorithm import get_display

import arabic_reshaper
import string
import numpy as np
import torch
def plot_attention(attention, sentence, predicted_sentence):
    fig = plt.figure(figsize=(10,10))
    ax = fig.add_subplot(1, 1,1)
    ax.matshow(attention, cmap='Greys')
    x1 = [0,1,2,3,4,5,6,7,8,9,10,]
    y1 = [0,1,2,3,4,5,6,7,8.9,10,11,12,13,14,15,16,17,18]
    
    fontdict = {'fontsize': 14}
    ax.set_xticks(x1)
    ax.set_yticks(y1)
    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)
    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)

sentence = "Enter this Hell today , for you kept disbelieving " 
    res  = 'آج اس دوزخ میں داخل ہو جاؤ اس وجہ سے کہ تم کفر کرتے رہے تھے ۔'
    result_tokens = list(reversed(res.split(' ')))
    result_detok = "".join([" "+i if not i.startswith("'") and i not in string.punctuation else i for i in result_tokens]).strip()
    result = get_display(arabic_reshaper.reshape(result_detok))
    
    
    weights   = [[0.0786, 0.0587, 0.0646, 0.0904, 0.0938, 0.1443, 0.1975, 0.0964,
              0.0964, 0.1141, 0.0765],
             [0.0875, 0.0596, 0.1108, 0.0844, 0.0975, 0.0948, 0.1450, 0.0800,
              0.1227, 0.1130, 0.1158],
             [0.0974, 0.1230, 0.0822, 0.1086, 0.0997, 0.0000, 0.0986, 0.1113,
              0.0984, 0.1016, 0.0000],
             [0.0000, 0.2078, 0.0650, 0.1168, 0.0917, 0.0668, 0.0700, 0.1127,
              0.1216, 0.1027, 0.0724],
             [0.1118, 0.1558, 0.1005, 0.1108, 0.0997, 0.0000, 0.0637, 0.1129,
              0.0854, 0.0862, 0.0936],
             [0.0980, 0.1075, 0.1062, 0.1000, 0.1000, 0.0851, 0.0941, 0.0961,
              0.1143, 0.1036, 0.1063],
             [0.0826, 0.1182, 0.0872, 0.1008, 0.0959, 0.0701, 0.1038, 0.0927,
              0.1462, 0.1171, 0.0964],
             [0.0671, 0.0194, 0.1130, 0.0563, 0.0842, 0.1034, 0.2585, 0.0000,
              0.1190, 0.1141, 0.1237],
             [0.1022, 0.0000, 0.0824, 0.1008, 0.1003, 0.1503, 0.1254, 0.1110,
              0.0756, 0.0956, 0.0844],
             [0.0000, 0.0730, 0.0959, 0.0927, 0.0991, 0.1075, 0.1382, 0.0000,
              0.1103, 0.1104, 0.1016],
             [0.0953, 0.0780, 0.0754, 0.0994, 0.0989, 0.1509, 0.1421, 0.0000,
              0.0806, 0.1007, 0.0808],
             [0.1029, 0.1179, 0.1029, 0.1039, 0.1007, 0.0917, 0.0868, 0.1027,
              0.1022, 0.0983, 0.1011],
             [0.0721, 0.0000, 0.0953, 0.0652, 0.0880, 0.1256, 0.2495, 0.0645,
              0.1055, 0.1131, 0.1063],
             [0.0953, 0.0562, 0.1045, 0.0000, 0.0991, 0.1268, 0.1499, 0.0884,
              0.0941, 0.1038, 0.1064],
             [0.0968, 0.1731, 0.1702, 0.0877, 0.0868, 0.0295, 0.0323, 0.0698,
              0.1425, 0.0811, 0.1416],
             [0.1117, 0.1934, 0.1207, 0.1069, 0.0953, 0.0599, 0.0422, 0.1010,
              0.0953, 0.0797, 0.0000],
             [0.1030, 0.1343, 0.0555, 0.1173, 0.0960, 0.1699, 0.0954, 0.1409,
              0.0000, 0.0834, 0.0585],
             [0.1223, 0.1610, 0.1025, 0.1122, 0.0000, 0.1030, 0.0555, 0.1195,
              0.0682, 0.0767, 0.0904]]

    attention_plot  = torch.tensor(weights,  dtype=torch.float32)


    #for attention_plot in at:

    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]

    plot_attention(attention_plot, sentence.split(' '), result.split(' '))